{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoder_layer(in_channels,out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1),\n",
    "        nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1)\n",
    "    )\n",
    "    \n",
    "\n",
    "class Unet_resnet(nn.Module):\n",
    "    def __init__(self,resnet_type,pretrained=False):\n",
    "        super(Unet_resnet,self).__init__()\n",
    "        if resnet_type == 'resnet18':\n",
    "            resnet = models.resnet.resnet18(pretrained)\n",
    "            encoder_out_channels = [64, 128, 256, 512]  \n",
    "        elif resnet_type == 'resnet34':\n",
    "            resnet = models.resnet.resnet34(pretrained)\n",
    "            encoder_out_channels = [64, 128, 256, 512]\n",
    "        elif resnet_type == 'resnet50':\n",
    "            resnet = models.resnet.resnet50(pretrained)\n",
    "            encoder_out_channels = [256, 512, 1024, 2048]\n",
    "        elif resnet_type == 'resnet101':\n",
    "            resnet = models.resnet.resnet101(pretrained)\n",
    "            encoder_out_channels = [256, 512, 1024, 2048]\n",
    "        elif resnet_type == 'resnet152':\n",
    "            resnet = models.resnet.resnet152(pretrained)\n",
    "            encoder_out_channels = [256, 512, 1024, 2048]\n",
    "        else:\n",
    "            raise ValueError(\"unexpected resnet_type\")\n",
    "\n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=1),\n",
    "            resnet.layer1\n",
    "        )\n",
    "        self.encoder2 = resnet.layer2\n",
    "        self.encoder3 = resnet.layer3\n",
    "        self.encoder4 = resnet.layer4\n",
    "        self.encoder5 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(encoder_out_channels[-1],2*encoder_out_channels[-1],kernel_size=3,padding=1),\n",
    "            nn.Conv2d(2*encoder_out_channels[-1],2*encoder_out_channels[-1],kernel_size=3,padding=1)\n",
    "        )\n",
    "        self.up4 = nn.ConvTranspose2d(2*encoder_out_channels[-1],encoder_out_channels[-1],stride=2,kernel_size=2)\n",
    "        self.decoder4 = make_decoder_layer(2*encoder_out_channels[-1],encoder_out_channels[-1])\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(2*encoder_out_channels[-2],encoder_out_channels[-2],stride=2,kernel_size=2)\n",
    "        self.decoder3 = make_decoder_layer(2*encoder_out_channels[-2],encoder_out_channels[-2])\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(2*encoder_out_channels[-3],encoder_out_channels[-3],stride=2,kernel_size=2)\n",
    "        self.decoder2 = make_decoder_layer(2*encoder_out_channels[-3],encoder_out_channels[-3])\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(2*encoder_out_channels[-4],encoder_out_channels[-4],stride=2,kernel_size=2)\n",
    "        self.decoder1 = make_decoder_layer(2*encoder_out_channels[-4],encoder_out_channels[-4])\n",
    "        \n",
    "        self.conv1x1 = nn.Conv2d(encoder_out_channels[-4],1,kernel_size=1)\n",
    "        \n",
    "        self.__init_weight()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.encoder1(x)\n",
    "        skipconnect1 = x\n",
    "        print(\"After encoder1, the shape is {}\".format(x.shape))\n",
    "        x = self.encoder2(x)\n",
    "        skipconnect2 = x\n",
    "        print(\"After encoder2, the shape is {}\".format(x.shape))\n",
    "        x = self.encoder3(x)\n",
    "        skipconnect3 = x\n",
    "        print(\"After encoder3, the shape is {}\".format(x.shape))\n",
    "        x = self.encoder4(x)\n",
    "        skipconnect4 = x\n",
    "        print(\"After encoder4, the shape is {}\".format(x.shape))\n",
    "        x = self.encoder5(x)\n",
    "        print(\"After encoder5, the shape is {}\".format(x.shape))\n",
    "        x = self.up4(x)\n",
    "        x = torch.cat((skipconnect4,x),dim=1)\n",
    "        x = self.decoder4(x)\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat((skipconnect3,x),dim=1)\n",
    "        x = self.decoder3(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat((skipconnect2,x),dim=1)\n",
    "        x = self.decoder2(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat((skipconnect1,x),dim=1)\n",
    "        x = self.decoder1(x)\n",
    "\n",
    "        x = self.conv1x1(x)\n",
    "        return x\n",
    "            \n",
    "    def __init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            if isinstance(m,nn.ConvTranspose2d): # 暂时用kaiming初始化\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out',nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoder1, the shape is torch.Size([1, 64, 224, 224])\n",
      "After encoder2, the shape is torch.Size([1, 128, 112, 112])\n",
      "After encoder3, the shape is torch.Size([1, 256, 56, 56])\n",
      "After encoder4, the shape is torch.Size([1, 512, 28, 28])\n",
      "After encoder5, the shape is torch.Size([1, 1024, 14, 14])\n",
      "torch.Size([1, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "unet = Unet_resnet('resnet34')\n",
    "#print(unet)\n",
    "input = torch.randn(1,1,224,224)\n",
    "output = unet(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoder1, the shape is torch.Size([1, 256, 224, 224])\n",
      "After encoder2, the shape is torch.Size([1, 512, 112, 112])\n",
      "After encoder3, the shape is torch.Size([1, 1024, 56, 56])\n",
      "After encoder4, the shape is torch.Size([1, 2048, 28, 28])\n",
      "After encoder5, the shape is torch.Size([1, 4096, 14, 14])\n",
      "torch.Size([1, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "unet = Unet_resnet('resnet101')\n",
    "#print(unet)\n",
    "input = torch.randn(1,1,224,224)\n",
    "output = unet(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
